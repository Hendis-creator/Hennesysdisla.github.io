<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.27.1 by Michael Rose
  Copyright 2013-2025 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Hyung Won Chung</title>
<meta name="description" content="Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.">


  <meta name="author" content="First Lastname">
  


<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Hyung Won Chung">
<meta property="og:title" content="Hyung Won Chung">
<meta property="og:url" content="https://hwchung2.github.io/">


  <meta property="og:description" content="Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.">












<link rel="canonical" href="https://hwchung2.github.io/">





  <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Person",
    "name": null,
    "url": "https://hwchung2.github.io/"
}
</script>









<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Hyung Won Chung Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- _includes/head/custom.html -->
<link rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css">

  </head>

  <body class="layout--splash" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Hyung Won Chung
          
        </a>
        <ul class="visible-links"></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      

<div id="main" role="main">
  <article class="splash" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="">
    
    
    

    <section class="page__content" itemprop="text">
      <!-- ░░░ Personal summary ░░░ -->

<!-- ░░░ Bio block with photo and links ░░░ -->
<div class="intro-flex">
  <div class="intro-left">          <!-- NEW wrapper -->
      <img src="/assets/images/profile.png" alt="Hyung Won Chung" class="intro-avatar" />
        <!-- social icons -->
        <p class="social-links">
          <a href="https://twitter.com/hwchung27" aria-label="Twitter">
            <i class="fa-brands fa-x-twitter"></i>
          </a>
          <a href="https://scholar.google.com/citations?user=1CAlXvYAAAAJ&amp;hl=en" aria-label="Google Scholar">
            <i class="ai ai-google-scholar"></i>
          </a>
          <a href="mailto:h.w.chung@gmail.com" aria-label="Email">
            <i class="fa-solid fa-envelope"></i>
          </a>
        </p>
  </div>

  <div class="intro-text">
    <p>
      I am a Research Scientist at
      <a href="https://openai.com/" target="_blank" rel="noopener">OpenAI</a>. 
    </p>

    <p>
      At OpenAI, my research focuses on reasoning and agents. I was a Foundational Contributor of
      <a href="https://openai.com/index/introducing-openai-o1-preview/" target="_blank" rel="noopener">o1-preview</a>
      (Sep. 2024),
      <a href="https://openai.com/index/learning-to-reason-with-llms/" target="_blank" rel="noopener">o1</a>
      (Dec. 2024),
      <a href="https://openai.com/index/introducing-deep-research/" target="_blank" rel="noopener">Deep Research</a>
      (Feb. 2025). I currently focus on coding agents and led the Codex mini model-training.
    </p>

    <p>
      Prior to OpenAI, I was at
      <a href="https://research.google.com/teams/brain/" target="_blank" rel="noopener">Google Brain</a>
      where I worked on whatever bottleneck stood in the way of further scaling: building JAX-based large-scale training system (T5X), training large models (e.g. PaLM), instruction fine-tuning (Flan-PaLM and Flan-T5 model families) and reasoning.
    </p>

    <p>
      Prior to Google Brain, I did my PhD at
      <a href="https://www.mit.edu/" target="_blank" rel="noopener">MIT</a>.
    </p>

    <p>
      I am originally from South Korea (Korean name: 정형원) and currently live in
      Mountain View, CA.
    </p>

  </div>
</div>

<h2 id="selected-work-at-openai">Selected work at OpenAI</h2>

<div id="openai-videos" class="video-grid">

<!-- ░░░ Visible on load ░░░ -->
<figure class="video-item">
  <figcaption>o1 launch livestream</figcaption>
  <iframe src="https://www.youtube.com/embed/iBfQTnA2n2s?start=21&amp;autoplay=1&amp;mute=1&amp;playsinline=1&amp;rel=0" title="o1 livestream" loading="lazy"></iframe>
</figure>

<figure class="video-item">
  <figcaption>Researchers behind o1</figcaption>
  <iframe src="https://www.youtube.com/embed/3k89FMJhZ00?playsinline=1&amp;rel=0&amp;mute=1" title="Researchers behind o1" loading="lazy"></iframe>
</figure>

<!-- ░░░ Hidden on load – NOTE: data-src, NOT src ░░░ -->
<figure class="video-item hidden">
  <figcaption>o1-preview demo 1</figcaption>
  <iframe data-src="https://www.youtube.com/embed/50W4YeQdnSg?playsinline=1&amp;rel=0&amp;mute=1" title="o1-preview demo 1" loading="lazy"></iframe>
</figure>

<figure class="video-item hidden">
  <figcaption>o1-preview demo 2</figcaption>
  <iframe data-src="https://www.youtube.com/embed/eZDmDn6Iq9Y?playsinline=1&amp;rel=0&amp;mute=1" title="o1-preview demo 2" loading="lazy"></iframe>
</figure>

<figure class="video-item hidden">
  <figcaption>o1-preview demo 3</figcaption>
  <iframe data-src="https://www.youtube.com/embed/1tX5aea0La4?playsinline=1&amp;rel=0" title="o1-preview demo 3" loading="lazy"></iframe>
</figure>

<figure class="video-item hidden">
  <figcaption>Codex mini demo</figcaption>
  <iframe data-src="https://www.youtube.com/embed/O-ZfXbfAMKU?rel=0&amp;mute=1" title="Codex mini demo" loading="lazy"></iframe>
</figure>


<figure class="video-item hidden">
  <figcaption>OpenAI Dev Day 2024</figcaption>
  <iframe data-src="https://www.youtube.com/embed/vlqEwE2wVr4?si=3Z34rUcHUbCM9TJE&amp;mute=1" title="OpenAI Dev Day 2024" loading="lazy"></iframe>
</figure>

</div>

<p><button id="openai-more-button" class="more-button" data-target="#openai-videos">Show more</button></p>

<hr />

<h2 id="selected-lectures-and-talks">Selected Lectures and Talks</h2>

<div id="talks-videos" class="video-grid">

<figure>
  <figcaption>Stanford CS 25 lecture</figcaption>
  <iframe src="https://www.youtube.com/embed/orDKvo8h71o?playsinline=1&amp;rel=0&amp;mute=1" title="Stanford CS25 lecture"></iframe>
</figure>

<figure>
  <figcaption>MIT EI seminar: “Don’t teach. Incentivize”</figcaption>
  <iframe src="https://www.youtube.com/embed/kYWUEV_e2ss?playsinline=1&amp;rel=0&amp;mute=1" title="MIT EI seminar: 'Don’t teach. Incentivize'"></iframe>
</figure>

<figure class="video-item hidden">
  <figcaption>Seoul National University seminar</figcaption>
  <iframe data-src="https://www.youtube.com/embed/dbo3kNKPaUA?si=i3C3vljqV0AsVca6&amp;mute=1" title="Seoul National University seminar"></iframe>
</figure>


<figure class="video-item hidden">
  <figcaption>NYU CSCI 2590 lecture</figcaption>
  <iframe data-src="https://www.youtube.com/embed/zjrM-MW-0y0?si=W7ZUtBpzK9X0xmix&amp;mute=1" title="NYU CSCI 2590 lecture" loading="lazy"></iframe>
</figure>

</div>

<p><button id="talks-more-button" class="more-button" data-target="#talks-videos">Show more</button></p>

<hr />

<h2 id="recent-papers-latest-first">Recent papers (latest first)</h2>

<ul id="papers-list" class="bibliography">


  <li>
    
      <strong><a href="https://arxiv.org/abs/2504.12516" target="_blank" rel="noopener">BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents</a></strong><br />
    
    Jason Wei, Zhiqing Sun, Spencer Papay, Scott McKinney, Jeffrey Han, Isa Fulford, Hyung Won Chung, Alex Tachard Passos, William Fedus, Amelia Glaese.<br />

    
  </li>

  <li>
    
      <strong><a href="https://arxiv.org/abs/2411.04368" target="_blank" rel="noopener">Measuring Short-Form Factuality in Large Language Models</a></strong><br />
    
    Jason Wei, Karina Nguyen, Hyung Won Chung, Yunxin Joy Jiao, Spencer Papay, Amelia Glaese, John Schulman, William Fedus.<br />

    
  </li>

  <li>
    
      <strong><a href="https://arxiv.org/abs/2412.16339" target="_blank" rel="noopener">Deliberative Alignment: Reasoning Enables Safer Language Models</a></strong><br />
    
    Melody Y. Guan, Manas Joglekar, Eric Wallace, Saachi Jain, Boaz Barak, Alec Heylar, Rachel Dias, Andrea Vallone, Hongyu Ren, Jason Wei, and others.<br />

    
  </li>

  <li>
    
      <strong><a href="https://arxiv.org/abs/2412.16720" target="_blank" rel="noopener">OpenAI o1 System Card</a></strong><br />
    
    Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, and others.<br />

    
  </li>

  <li>
    
      <strong><a href="https://arxiv.org/abs/2410.21276" target="_blank" rel="noopener">GPT-4o System Card</a></strong><br />
    
    Aaron Hurst, Adam Lerer, Adam P. Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, and others.<br />

    
  </li>

  <li>
    
      <strong><a href="https://arxiv.org/abs/2303.08774" target="_blank" rel="noopener">GPT-4 Technical Report</a></strong><br />
    
    Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, and others.<br />

    
  </li>

  <li>
    
      <strong><a href="https://arxiv.org/abs/2305.14705" target="_blank" rel="noopener">Flan-MoE: Scaling Instruction-Finetuned Language Models with Sparse Mixture of Experts</a></strong><br />
    
    Sheng Shen, Le Hou, Yanqi Zhou, Nan Du, Shayne Longpre, Jason Wei, Hyung Won Chung, Barret Zoph, William Fedus, Xinyun Chen, and others.<br />

    
  </li>

  <li>
    
      <strong><a href="https://arxiv.org/abs/2210.11416" target="_blank" rel="noopener">Scaling Instruction-Finetuned Language Models</a></strong><br />
    
    Hyung Won Chung*, Le Hou*, Shayne Longpre*, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, Jason Wei*.<br />

    
      <cite>
        Journal of Machine Learning Research
        
        
         (2024)
      </cite>
    
  </li>

  <li>
    
      <strong><a href="https://arxiv.org/abs/2204.02311" target="_blank" rel="noopener">PaLM: Scaling Language Modeling with Pathways</a></strong><br />
    
    Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung and 67 others.<br />

    
      <cite>
        Journal of Machine Learning Research
        
        
         (2024)
      </cite>
    
  </li>

  <li>
    
      <strong><a href="https://www.nature.com/articles/s41586-023-06291-2" target="_blank" rel="noopener">Large Language Models Encode Clinical Knowledge</a></strong><br />
    
    Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won Chung, ….<br />

    
      <cite>
        Nature
         620
        , 172–180
         (2023)
      </cite>
    
  </li>

  <li>
    
      <strong><a href="https://arxiv.org/abs/2203.17189" target="_blank" rel="noopener">Scaling Up Models and Data with t5x and seqio</a></strong><br />
    
    Adam Roberts*, Hyung Won Chung*, Anselm Levskaya*, Gaurav Mishra*, James Bradbury\*, Daniel Andor, Sharan Narang, Brian Lester, Colin Gaffney, Afroz Mohiuddin, Curtis Hawthorne, Aitor Lewkowycz, Alex Salcianu, Marc van Zee, Jacob Austin, Sebastian Goodman, Livio Baldini Soares, Haitang Hu, Sasha Tsvyashchenko, Aakanksha Chowdhery, Jasmijn Bastings, Jannis Bulian, Xavier Garcia, Jianmo Ni, Andrew Chen, Kathleen Kenealy, Jonathan H. Clark, Stephan Lee, Dan Garrette, James Lee-Thorp, Colin Raffel, Noam Shazeer, Marvin Ritter, Maarten Bosma, Alexandre Passos, Jeremy Maitin-Shepard, Noah Fiedel, Mark Omernick, Brennan Saeta, Ryan Sepassi, Alexander Spiridonov, Joshua Newlan, Andrea Gesmundo.<br />

    
      <cite>
        Journal of Machine Learning Research
        
        
         (2024)
      </cite>
    
  </li>

  <li>
    
      <strong><a href="https://arxiv.org/abs/2304.09151" target="_blank" rel="noopener">UniMax: Fairer and more Effective Language Sampling for Large-Scale Multilingual Pretraining</a></strong><br />
    
    Hyung Won Chung<sup>*</sup>, Noah Constant<sup>*</sup>, Xavier Garcia<sup>*</sup>, Adam Roberts, Yi Tay, Sharan Narang, Orhan Firat.<br />

    
      <cite>
        ICLR
        
        
         (2023)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2301.13688" target="_blank" rel="noopener">The Flan Collection: Designing Data and Methods for Effective Instruction Tuning</a></strong><br />
    
    Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V. Le, Barret Zoph, Jason Wei, Adam Roberts.<br />

    
      <cite>
        ICML
        
        
         (2023)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2211.05100" target="_blank" rel="noopener">BLOOM: A 176B-Parameter Open-Access Multilingual Language Model</a></strong><br />
    
    BigScience Workshop (300+ authors).<br />

    
      <cite>
        arXiv
        
        
         (2022)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2210.11399" target="_blank" rel="noopener">Transcending Scaling Laws with 0.1 % Extra Compute</a></strong><br />
    
    Yi Tay, Jason Wei, Hyung Won Chung, and 20 others.<br />

    
      <cite>
        arXiv
        
        
         (2022)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2210.09261" target="_blank" rel="noopener">Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them</a></strong><br />
    
    Mirac Suzgun, Nathan Scales, Nathanael Scharli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V. Le, Ed H. Chi, Denny Zhou, Jason Wei.<br />

    
      <cite>
        arXiv
        
        
         (2022)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2210.03057" target="_blank" rel="noopener">Language Models are Multilingual Chain-of-Thought Reasoners</a></strong><br />
    
    Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, Jason Wei.<br />

    
      <cite>
        arXiv
        
        
         (2022)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2207.10551" target="_blank" rel="noopener">Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling?</a></strong><br />
    
    Yi Tay, Mostafa Dehghani, Samira Abnar, Hyung Won Chung, William Fedus, Jinfeng Rao, Sharan Narang, Vinh Q. Tran, Dani Yogatama, Donald Metzler.<br />

    
      <cite>
        arXiv
        
        
         (2022)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2205.05131" target="_blank" rel="noopener">UL2: Unifying Language Learning Paradigms</a></strong><br />
    
    Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Jason Wei, Xuezhi Wang, Hyung Won Chung, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Denny Zhou, Neil Houlsby, Donald Metzler.<br />

    
      <cite>
        arXiv
        
        
         (2022)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2204.05832" target="_blank" rel="noopener">What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?</a></strong><br />
    
    Thomas Wang, Adam Roberts, Daniel Hesslow, Teven Le Scao, Hyung Won Chung, Iz Beltagy, Julien Launay, Colin Raffel.<br />

    
      <cite>
        ICML
        
        
         (2022)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2204.02311" target="_blank" rel="noopener">PaLM: Scaling Language Modeling with Pathways</a></strong><br />
    
    Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung and 67 others.<br />

    
      <cite>
        arXiv
        
        
         (2022)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2203.17189" target="_blank" rel="noopener">Scaling Up Models and Data with t5x and seqio</a></strong><br />
    
    Adam Roberts<sup>*</sup>, Hyung Won Chung<sup>*</sup>, Anselm Levskaya<sup>*</sup>, Gaurav Mishra<sup>*</sup>, James Bradbury<sup>*</sup>.<br />

    
      <cite>
        arXiv
        
        
         (2022)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2109.10686" target="_blank" rel="noopener">Scale Efficiently: Insights from Pre-training and Fine-tuning Transformers</a></strong><br />
    
    Yi Tay, Mostafa Dehghani, Jinfeng Rao, William Fedus, Samira Abnar, Hyung Won Chung, Sharan Narang, Dani Yogatama, Ashish Vaswani, Donald Metzler.<br />

    
      <cite>
        ICLR
        
        
         (2022)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2106.12672" target="_blank" rel="noopener">Charformer: Fast Character Transformers via Gradient-based Subword Tokenization</a></strong><br />
    
    Yi Tay, Vinh Q. Tran, Sebastian Ruder, Jai Gupta, Hyung Won Chung, Dara Bahri, Zhen Qin, Simon Baumgartner, Cong Yu, Donald Metzler.<br />

    
      <cite>
        ICLR
        
        
         (2022)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2102.11972" target="_blank" rel="noopener">Do Transformer Modifications Transfer Across Implementations and Applications?</a></strong><br />
    
    Sharan Narang, Hyung Won Chung, Yi Tay, William Fedus, Thibault Fevry, Michael Matena, Karishma Malkan, Noah Fiedel, Noam Shazeer, Zhenzhong Lan, Yanqi Zhou, Wei Li, Nan Ding, Jake Marcus, Adam Roberts, Colin Raffel.<br />

    
      <cite>
        EMNLP
        
        
         (2021)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2102.01335" target="_blank" rel="noopener">Neural Data Augmentation via Example Extrapolation</a></strong><br />
    
    Kenton Lee<sup>*</sup>, Kelvin Guu<sup>*</sup>, Luheng He<sup>*</sup>, Tim Dozat<sup>*</sup>, Hyung Won Chung<sup>*</sup>.<br />

    
      <cite>
        arXiv
        
        
         (2021)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2010.12821" target="_blank" rel="noopener">Rethinking Embedding Coupling in Pre-trained Language Models</a></strong><br />
    
    Hyung Won Chung<sup>*</sup>, Thibault Févry<sup>*</sup>, Henry Tsai, Melvin Johnson, Sebastian Ruder.<br />

    
      <cite>
        ICLR
        
        
         (2021)
      </cite>
    
  </li>

  <li class="hidden">
    
      <strong><a href="https://arxiv.org/abs/2010.12777" target="_blank" rel="noopener">Improving Multilingual Models with Language-Clustered Vocabularies</a></strong><br />
    
    Hyung Won Chung<sup>*</sup>, Dan Garrette, Kiat Chuan Tan, Jason Riesa.<br />

    
      <cite>
        EMNLP
        
        
         (2020)
      </cite>
    
  </li>

</ul>

<p><button id="papers-more-button" class="more-button" data-target="#papers-list">
  Show more
</button></p>

<!-- put this at the very end of index.md (or whatever page),            -->
<!-- right before the closing markdown ‘---’ or before any footer include -->

<script>
/* unified handler from previous message */
document.addEventListener("DOMContentLoaded", () => {
  document.querySelectorAll(".more-button").forEach(btn => {
    btn.addEventListener("click", () => {
      const target = document.querySelector(btn.dataset.target);
      if (!target) return;

      target.querySelectorAll(".hidden").forEach(fig => {
        fig.classList.remove("hidden");
        const ifr = fig.querySelector("iframe[data-src]");
        if (ifr) ifr.src = ifr.dataset.src;
      });

      btn.remove();
    });
  });
});
</script>


    </section>
  </article>
</div>

      
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://instagram.com/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i> Instagram</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 <a href="https://hwchung2.github.io">Hyung Won Chung</a>. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/jekyll-themes/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>









  </body>
</html>
